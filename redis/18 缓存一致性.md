# 缓存一致性

缓存一致性是指，在使用缓存机制为持久化组件提供查询性能的同时，对数据的更新要保证**缓存中数据与持久化数据一致**。如果出现数据不一致，基于从不一致的数据在业务处理时可能得到一个错误的结果。

**从更新策略上来说大致可以分为以下几种：**

1. 先更新缓存，再持久化
2. 先持久化，再更新缓存
3. 先删除缓存，再持久化（等待后续读取时，从持久化数据中lazy的加载到缓存）
4. 先持久化，再删除缓存（等待后续读取时，从持久化数据中lazy的加载到缓存）

**下面将通过不同的场景来渐进的讨论这些问题。可以发现随着场景的复杂度的变化有些策略可能就不太适用了。**

1. 单机单线程环境（缓存和持久化组件在同一台机器，并且处理请求是单线程的）
2. 分布式单线程（缓存和持久化组件分布在不同机器上，处理请求是单线程）
3. 分布式多线程（缓存和持久化组件分布在不同机器上，处理请求是多线程的）
4. 分布式多线程高并发（缓存和持久化组件分布在不同机器上，处理请求是多线程的，并且随时会有大量的请求过来）

## 单机单线程环境下缓存一致性

在单机单线程环境，**使用任何策略都可以保证缓存一致性**，因为单机，缓存和持久化组件都在同一台机器，**不存在网络通信的不确定性**，并且**单线程，所有的请求都是串行执行**，可以保证一次只有一个请求访问到缓存或者持久化组件。对于上述4种更新策略都可以满足一致性需求

## 分布式单线程环境下缓存一致性

前面说到在单机单线程环境下使用任何策略都可以保证缓存一致性，这是因为没有网络因素和并发的干扰。那么将缓存抽离放到另外的一台机器上，引入了网络通信的不确定性之后会有问题吗？

1. 先更新缓存，再持久化，**不能保证一致性**，由于存在网络通信的不确定性。考虑以下情况
   1. 发起缓存更新请求后，如果**出现超时异常**，此时缓存服务器的操作对于客户端来说是未知的，更新了缓存？没更新缓存？
   2. 此时客户端不管保存或者不保存都不合适，都有可能造成数据不一致
2. 先持久化，再更新缓存，**情况与策略1相同，不能保证一致性。**出现超时异常时，我到底是更新还是回滚呢？
3. 先删除缓存，再持久化，**可以保证一致性**。考虑以下情况
   1. 删除缓存成功，则直接进行数据持久化
   2. 缓存删除失败，不进行后续操作
   3. 缓存删除出现超时异常，此时缓存的状态是不确定的，可能被删除也可能存在，此时只要不进行后续操作即可，可以保证缓存和持久化组件数据是一致的
4. 先持久化，再删除缓存，**情况去策略3相同，可以保证一致性**，对于删除缓存失败或者超时的场景只需要将数据回滚即可

**可以看到在单线程环境下，引入了网络因素之后，对于缓存的更新操作无论是放到持久化前还是持久化之后都没法保证数据的一致性，如果是删除缓存的操作则可以保证数据一致性**

## 分布式多线程环境下缓存一致性（正常业务环境）

引入多线程之后情况就比较复杂了，**这里先假设网络是可靠的**，然后再对四种策略进行考察。引入多线程之后会有哪些问题？

1. 先更新缓存，再持久化，**不能保证一致性**，考虑以下情况
   1. 线程A更新缓存
   2. 线程B更新缓存
   3. 线程B数据持久化
   4. 线程A数据持久化
   5. 此时缓存中数据是B线程的，持久化组件中数据是A线程的
2. 先持久化，再更新缓存，**情况与策略1相同，不能保证一致性。**
   1. 线程A数据持久化
   2. 线程B数据持久化
   3. 线程B更新缓存
   4. 线程A更新缓存
   5. 此时缓存中数据是A线程的，持久化组件中数据是B线程的
3. 先删除缓存，再持久化，**不能保证数据一致性**，考虑以下情况
   1. 线程A删除缓存
   2. 线程B查询缓存miss，查持久化组件获取数据，将数据写入缓存
   3. 线程A数据持久化
   4. 此时缓存中是旧值，持久化组件中是新值
4. 先持久化，再删除缓存，**不能保证数据一致性**，考虑以下情况
   1. 缓存刚好过期（一般会设置过期时间）
   2. 线程A查询缓存miss，查询持久化组件获取数据
   3. 线程B数据持久化
   4. 线程B删除缓存（一次空删）
   5. 线程A将查询到的旧值写入缓存
   6. 此时缓存中是旧值，持久化组件中是新值

可以看到引入了多线程之后情况变得复杂了，原先能够保证一致性的策略3和策略4都没法保证一致性了，那么怎么处理才能保证数据一致性呢？这里不对策略1与策略2进行优化（分布式的情况根本就没法保证一致性）

可以发现，策略3与策略4的数据不一致都是写读并发造成的问题。有以下解决办法：

1. 对所有访问持久化组件的操作做加锁处理，这样对于持久化组件的访问就变成了单线程了，避免了读写并发的问题
2. 直接加锁会影响一些吞吐量，可以考虑在读持久化组件的地方加上读锁，在更新端加上写锁，这样可以提高一点吞吐量
3. 上述加锁的操作可以保证数据一致性但会对性能造成影响，如果不加锁，则会出现长时间的数据不一致，可能直到下一次缓存过期数据才会变为一致。仔细分析策略3和策略4可以发现，策略3出现数据不一致的情况几率比较大，而策略4出现数据不一致的情况则比较少，因为更新操作普遍来讲都是比查询操作慢的，线程B可能没有更新完线程A就写入缓存了，之后线程B会将其删除，可以考虑**使用延时双删的办法优化策略4**，即在进行一次删除之安排一个定时器比如1s之后再去删除一次，这样可以保证数据最终是一致的，最多也只会有1s的数据不一致
4. 这里可以得出**策略4是一个比较好的保证数据一致性的方案**，但是采用**延时双删的办法对业务侵入性比较大**，而且对于第二次删除失败的情况比较难以处理，这里给出一个比较成熟的方案。使用一种组件监听持久化组件的数据变更，将其投入MQ中，在MQ的消费端进行缓存的删除操作或者更新操作，由于消息是有序的，在消费端使用一条线程消费消息，只有操作缓存成功才ACK，借助MQ**只有ACK了之后才算消费成功**的机制保证对缓存的操作一定成功，这样可以保证缓存的**最终一致性**

## 分布式多线程高并发环境下缓存一致性（正常业务环境）

前面对分布式多线程下的缓存一致性方案进行过讨论，得出了**策略4是一个比较好的方案**，并且提供了两种无锁实现，即**延时双删**和**异步MQ更新**，这里要说一下，这些两个方案都是**最终一致性**的解决方案，也就是说**会存在一小段时间的缓存不一致**，如果**想要实现强一致，则可以考虑加锁操作**，但是这会对性能造成很大的影响。

从耦合性和实现难易程度层面考虑的话，延时双删耦合度比较高，失败重试设计比较麻烦，而异步MQ更新的难点在于持久化组件变更消息的监听。但是业内已经有比较成熟的组件可以使用了（阿里的canal），但是如果该组件不支持监听我们使用的持久化组件则需要自己实现。综合考虑**异步MQ更新胜出**。

那么在高并发的情况下，我们如何处理缓存缓存更新的问题呢？这个问题其实是一个缓存击穿的问题解决，如果我**采用异步MQ更新**的方案做缓存一致性则方案如下：

1. **双重检查机制**，在MQ消费的时候直接删除缓存中的key，在高并发读取时，缓存出现miss，此时对读取操作加互斥锁，并在临界区内做二次检查（double check），再次miss时才查询持久化组件，然后写入缓存。这样可以保证只有一个请求会命中持久化组件，其他请求只会命中缓存，但是在**超高并发下不太好使假如有1000个请求都在同一时刻miss了，则这1000个请求都会排队等待进入临界区，而临界区内其实是做了一次远程调用时间也不会短**
2. **双key差异更新**，在缓存中将数据缓存到AB两个key中，在查询端先查询A，如果miss则查询B。在MQ消费的这一端则**不能简单的删除某个key，而是修改缓存**，具体的先修改B，再修改A，这样就可以保证没有任何请求会打到持久化设备，所有的请求都打在了AB两个key上了

## 使用异步MQ更新的好处

使用MQ做异步更新，操作是异步的，即使缓存组件出现问题，无非就是缓存不可用而已，等到缓存组件恢复，就可以正常ack了，**正常的更新业务还是能够开展**。

然后就是查询端的解决方案，如果缓存组件出现问题无法提供服务，可以考虑做服务降级，**一部分请求直接返回友好的提示，一部分请求可以允许访问到持久化组件直接获取数据**。这样的设计系统的可用性就非常好了，不会过度的依赖某个组件。

相较于延时双删这种方案，如果缓存不可用则完全没法开展更新业务，耦合性太高

## canal

canal是阿里巴巴 MySQL binlog 增量订阅&消费组件，基于日志增量订阅和消费的业务包括

- 数据库镜像
- 数据库实时备份
- 索引构建和实时维护(拆分异构索引、倒排索引等)
- **业务 cache 刷新**
- 带业务逻辑的增量数据处理

当前的 canal 支持源端 MySQL 版本包括 5.1.x , 5.5.x , 5.6.x , 5.7.x , 8.0.x

工作原理是模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议，MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )，canal 解析 binary log 对象(原始为 byte 流)